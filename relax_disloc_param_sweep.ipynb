{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Relax displacements with a basal dislocation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a sense for the output: Make a single pyGMT plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygmt\n",
    "\n",
    "directory = \"/Users/jloveles/Documents/relax/examples/tutorials/output2_dipping\"\n",
    "pathname = directory + \"/000-east.grd\"\n",
    "faultname = directory + \"/rfaults-001.xy\"\n",
    "grid = pygmt.load_dataarray(pathname)\n",
    "\n",
    "# Get z limits from grdinfo\n",
    "info = pygmt.grdinfo(pathname, nearest_multiple=\"+a0.1\")\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "pygmt.makecpt(cmap=\"haxby\", series=info[2:])\n",
    "fig.grdimage(grid=grid, projection=\"X10c\", frame=\"ag\")\n",
    "fig.colorbar(frame=[\"x+lDisplacement\", \"y+lmm\"])\n",
    "\n",
    "pygmt.makecpt(cmap=\"gray\", series=[0, 2000])\n",
    "fig.plot(faultname, cmap=True, close=True, pen=\"2p\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up triangular dislocation sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_horizon(x, y, z, el_size):\n",
    "    # Makes a simple ~horizon of triangular dislocation elements using Gmsh\n",
    "    # x, y are 2-element arrays defining horizontal bounds\n",
    "    # z is a scalar giving depth \n",
    "    # el_size gives nominal element size \n",
    "\n",
    "    import gmsh\n",
    "    import meshio\n",
    "    \n",
    "    # Mesh construction using Gmsh\n",
    "    gmsh.initialize()\n",
    "    # Define points\n",
    "    gmsh.model.geo.addPoint(x[0], y[0], z+0.01, el_size, 1)\n",
    "    gmsh.model.geo.addPoint(x[1], y[0], z-0.01, el_size, 2)\n",
    "    gmsh.model.geo.addPoint(x[1], y[1], z-0.01, el_size, 3)\n",
    "    gmsh.model.geo.addPoint(x[0], y[1], z+0.01, el_size, 4)\n",
    "    # Boundary lines\n",
    "    gmsh.model.geo.addLine(1, 2, 1)\n",
    "    gmsh.model.geo.addLine(2, 3, 2)\n",
    "    gmsh.model.geo.addLine(3, 4, 3)\n",
    "    gmsh.model.geo.addLine(4, 1, 4)\n",
    "    # Perimeter\n",
    "    gmsh.model.geo.addCurveLoop([1, 2, 3, 4], 1)\n",
    "    # Surface\n",
    "    gmsh.model.geo.addPlaneSurface([1], 1)\n",
    "    gmsh.model.geo.synchronize()\n",
    "    # Generate and write. Writing a file allows use of meshio, consistent with celeri codes\n",
    "    gmsh.model.mesh.generate(2)\n",
    "    gmsh.write(\"file.msh\")\n",
    "    gmsh.finalize()\n",
    "\n",
    "    # Read and parse mesh\n",
    "    mesh = meshio.read(\"file.msh\")\n",
    "    fault_pts = mesh.points\n",
    "    fault_tri = meshio.CellBlock(\"triangle\", mesh.get_cells_type(\"triangle\")).data\n",
    "    return fault_pts, fault_tri"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define source mesh and horizon, calculate partials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cutde.halfspace as cutde_halfspace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xa\n",
    "import addict\n",
    "import celeri\n",
    "\n",
    "# Get stations from grid plotted above\n",
    "gsubset = 10 # Subset of grid points: increment every gsubset points along grid\n",
    "xg = np.array(grid.x)\n",
    "yg = np.array(grid.y)\n",
    "Xg, Yg = np.meshgrid(xg, yg)\n",
    "obsg = np.array([Xg[0::gsubset, 0::gsubset], Yg[0::gsubset, 0::gsubset], 0*Yg[0::gsubset, 0::gsubset]]).reshape((3, -1)).T.copy()\n",
    "\n",
    "# Define source fault\n",
    "meshes = []\n",
    "meshes.append(addict.Dict())\n",
    "source_len = 2\n",
    "source_ldep = 1\n",
    "source_bdep = 0\n",
    "source_dip = 20*np.pi/180\n",
    "# Fault coordinates\n",
    "meshes[0].coords = np.array([[0.01, -source_len/2, source_bdep], [0.01, source_len/2, source_bdep], [0.01+source_ldep*np.cos(source_dip), source_len/2, -source_ldep*np.sin(source_dip)], [0.01+source_ldep*np.cos(source_dip), -source_len/2, -source_ldep*np.sin(source_dip)]])\n",
    "meshes[0].verts = np.array([[0, 1, 2], [0, 2, 3]], dtype=np.int64)\n",
    "\n",
    "# Define horizontal mesh\n",
    "meshes.append(addict.Dict())\n",
    "meshes[1].coords, meshes[1].verts = tri_horizon([-10, 10], [-10, 10], -2, 1)\n",
    "# nsource_tri = np.shape(meshes[0].verts)[0]\n",
    "nsource_tri = 0\n",
    "nhoriz_tri = np.shape(meshes[1].verts)[0]\n",
    "ntri = nsource_tri + nhoriz_tri\n",
    "\n",
    "# Concatenate source and horizontal\n",
    "source_tri_pts = meshes[0].coords[meshes[0].verts]\n",
    "horiz_tri_pts = meshes[1].coords[meshes[1].verts]\n",
    "all_tri_pts = np.concatenate((source_tri_pts, horiz_tri_pts), axis=0)\n",
    "\n",
    "# Calculate element normals, strike and dip\n",
    "meshes[0].normal_vector = np.cross(source_tri_pts[:, 1, :] - source_tri_pts[:, 0, :], source_tri_pts[:, 2, :] - source_tri_pts[:, 0, :])\n",
    "meshes[1].normal_vector = np.cross(horiz_tri_pts[:, 1, :] - horiz_tri_pts[:, 0, :], horiz_tri_pts[:, 2, :] - horiz_tri_pts[:, 0, :])\n",
    "\n",
    "# Calculate TDE partials for the subset array\n",
    "disp_mat = cutde_halfspace.disp_matrix(obs_pts=obsg, tris=horiz_tri_pts, nu=0.25)\n",
    "\n",
    "# Calculate TDE partials for the full array, for comparison with full Relax grid\n",
    "obsg_full = np.array([Xg, Yg, 0*Yg]).reshape((3, -1)).T.copy()\n",
    "disp_mat_full = cutde_halfspace.disp_matrix(obs_pts=obsg_full, tris=horiz_tri_pts, nu=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up inversion of Relax displacements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get triangular smoothing matrix\n",
    "\n",
    "operators = addict.Dict()\n",
    "celeri.get_all_mesh_smoothing_matrices_simple(meshes, operators)\n",
    "\n",
    "# Assemble matrices\n",
    "assembled_mat = np.zeros((np.size(obsg)+3*ntri, 3*ntri))\n",
    "# Insert elastic partials\n",
    "assembled_mat[0:np.size(obsg), :] = disp_mat.reshape((-1, 3*ntri))\n",
    "# Insert smoothing matrices\n",
    "source_row_start = np.size(obsg)\n",
    "source_row_end = np.size(obsg) + 3*nsource_tri\n",
    "# assembled_mat[source_row_start:source_row_end, 0:3*nsource_tri] = operators.smoothing_matrix[0].toarray()\n",
    "assembled_mat[source_row_end:, 3*nsource_tri:] = operators.smoothing_matrix[1].toarray()\n",
    "\n",
    "# Assemble weighting vector\n",
    "smoothing_weight = 1e-3\n",
    "weights = np.ones((np.shape(assembled_mat)[0], 1))\n",
    "weights[source_row_start:] = smoothing_weight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential reading and inversion of displacement grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "###\n",
    "### PARAMETER RANGES\n",
    "###\n",
    "\n",
    "# List of dips to test\n",
    "dips = np.arange(10, 100, 10)\n",
    "\n",
    "# List of depth multipliers: \n",
    "# Fault depth will be calculated, then multiplied by depth multiplier to define thickness of elastic layer\n",
    "depth_mults = np.arange(1, 4, 1).astype(float)\n",
    "\n",
    "# List of viscosities to test\n",
    "# Framed as gammadot = 1/Maxwell time\n",
    "maxwell_times = np.array([1, 5, 10])\n",
    "viscosities = 1./maxwell_times\n",
    "\n",
    "###\n",
    "### ALLOCATE SPACE FOR ALL RESULTS\n",
    "###\n",
    "\n",
    "# Allocate space for estimated slip and predicted displacements\n",
    "# Hard coded for 500 time steps; can trim unused columns later\n",
    "n_trials = len(dips)*len(depth_mults)*len(viscosities)\n",
    "est_slip = np.zeros((3*ntri, 500, n_trials))\n",
    "pred_disp = np.zeros((obsg_full.size, 500, n_trials))\n",
    "time_vectors = np.zeros(500, n_trials)\n",
    "\n",
    "# Allocate space for data vector\n",
    "data_vector = np.zeros(source_row_start+3*ntri)\n",
    "\n",
    "# Calculate model covariance\n",
    "cov = np.linalg.inv(assembled_mat.T * weights.T @ assembled_mat) \n",
    "\n",
    "\n",
    "totalidx = -1\n",
    "for dipi in range(len(dips)):\n",
    "    for depthi in range(len(depth_mults)):\n",
    "        for visci in range(len(viscosities)):\n",
    "            totalidx =+ 1\n",
    "            sh_name = 'dip{:}_z{:0.2}_eta{:0.2}.sh'.format(dips[dipi], depth_mults[depthi], viscosities[visci])\n",
    "            directory = f\"./tutorials/parameter_ranges/output_{sh_name[:-3]}\".format()\n",
    "            time_vector = np.loadtxt(directory + \"/time.txt\", unpack=False)\n",
    "            time_vectors[0:len(time_vector), totalidx] = time_vector\n",
    "            \n",
    "            # Read sequence of displacement grd files and invert\n",
    "            e_disp_file_list = sorted(glob.glob(directory + \"/*-relax-east.grd\"))\n",
    "            n_disp_file_list = sorted(glob.glob(directory + \"/*-relax-north.grd\"))\n",
    "            u_disp_file_list = sorted(glob.glob(directory + \"/*-relax-up.grd\"))\n",
    "\n",
    "            # Read each file and invert \n",
    "            for i in range(len(e_disp_file_list)):\n",
    "                # Read components\n",
    "                e_disp = pygmt.load_dataarray(e_disp_file_list[i])\n",
    "                n_disp = pygmt.load_dataarray(n_disp_file_list[i])\n",
    "                u_disp = pygmt.load_dataarray(u_disp_file_list[i])\n",
    "                # Take the same subset as when setting up partials\n",
    "                disp_array = np.array([e_disp[0::gsubset, 0::gsubset], n_disp[0::gsubset, 0::gsubset], u_disp[0::gsubset, 0::gsubset]]).reshape((3, -1)).T.copy()\n",
    "                data_vector[0:source_row_start] = disp_array.flatten()\n",
    "                # Estimate slip using pre-calculated covariance\n",
    "                est_slip[:, i, totalidx] = cov @ assembled_mat.T * weights.T @ data_vector \n",
    "                # Predict displacement at the full grid resolution\n",
    "                pred_disp[:, i, totalidx] = disp_mat_full.reshape((-1, 3*ntri)).dot(est_slip[:, i])   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displacement grids (pyGMT; north component only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get z limits from grdinfo\n",
    "info = pygmt.grdinfo(n_disp_file_list[-1], nearest_multiple=\"+a0.01\")\n",
    "\n",
    "# Make a time series array for all north displacements\n",
    "e_disp_array = np.zeros((np.shape(obsg_full)[0], len(e_disp_file_list)))\n",
    "n_disp_array = np.zeros((np.shape(obsg_full)[0], len(n_disp_file_list)))\n",
    "u_disp_array = np.zeros((np.shape(obsg_full)[0], len(u_disp_file_list)))\n",
    "\n",
    "# For all time steps,\n",
    "for i in range(len(n_disp_file_list)):\n",
    "    # Convert predicted displacements to xarrays\n",
    "    eastdispg = xa.DataArray.copy(grid)\n",
    "    eastdispg.values = np.reshape(pred_disp[0::3, i], (256, 256))\n",
    "    northdispg = xa.DataArray.copy(grid)\n",
    "    northdispg.values = np.reshape(pred_disp[1::3, i], (256, 256))\n",
    "    updispg = xa.DataArray.copy(grid)\n",
    "    updispg.values = np.reshape(pred_disp[2::3, i], (256, 256))\n",
    "    # Read in Relax displacements\n",
    "    e_disp = pygmt.load_dataarray(e_disp_file_list[i])\n",
    "    n_disp = pygmt.load_dataarray(n_disp_file_list[i])\n",
    "    u_disp = pygmt.load_dataarray(u_disp_file_list[i])\n",
    "    # Add to an array for later displacement vs. time plot\n",
    "    e_disp_array[:, i] = np.array(e_disp).flatten()\n",
    "    n_disp_array[:, i] = np.array(n_disp).flatten()\n",
    "    u_disp_array[:, i] = np.array(u_disp).flatten()\n",
    "    # Residual displacements: Relax - TDE predicted (not currently plotted)\n",
    "    diffgrid = n_disp - northdispg\n",
    "    \n",
    "    # pyGMT figure: 2 panels, TDE and Relax\n",
    "    # fig = pygmt.Figure()\n",
    "    # pygmt.makecpt(cmap=\"haxby\", series=info[2:])\n",
    "    # with fig.subplot(nrows=1, ncols=2, figsize=(\"22c\", \"6c\")):\n",
    "    #      with fig.set_panel(panel=0):\n",
    "    #          # TDE predictions\n",
    "    #          fig.grdimage(grid=northdispg, projection=\"X10c\", frame=[\"ag\", f\"+tTDE, step {i}\"])\n",
    "    #          fig.colorbar(frame=[\"x+lDisplacement\", \"y+lmm\"])\n",
    "    #      with fig.set_panel(panel=1):\n",
    "    #          # Relax grid\n",
    "    #          fig.grdimage(grid=n_disp, projection=\"X10c\", frame=[\"ag\", f\"+tRelax, step {i}\"])\n",
    "    #          fig.colorbar(frame=[\"x+lDisplacement\", \"y+lmm\"])\n",
    "\n",
    "    # fig.show()\n",
    "    # fig.savefig(f\"png/ndisplacement_{i}.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basal slip distribution (matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plot a single mesh; modified from celeri_vis.py\n",
    "def plot_mesh(mesh, fill_value, ax):\n",
    "    x_coords = mesh.coords[:, 0]\n",
    "    y_coords = mesh.coords[:, 1]\n",
    "    vertex_array = np.asarray(mesh.verts)\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    xy = np.c_[x_coords, y_coords]\n",
    "    verts = xy[vertex_array]\n",
    "    pc = matplotlib.collections.PolyCollection(\n",
    "        verts, edgecolor=\"none\", cmap=\"rainbow\"\n",
    "    )\n",
    "    pc.set_array(fill_value)\n",
    "    ax.add_collection(pc)\n",
    "    ax.autoscale()\n",
    "    pc.set_clim([-0.02, 0.02])\n",
    "    plt.colorbar(pc, label=\"Strike-slip (N-S)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "for i in range(len(n_disp_file_list)):\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_mesh(meshes[1], -est_slip[3*nsource_tri+1::3, i], ax)\n",
    "    ax.plot([-7, 7, 7, -7, -7], [-7, -7, 7, 7, -7], 'k')\n",
    "    ax.set_title(f\"Time step {i}\")\n",
    "    # fig.savefig(f\"png/horizslip_{i}.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displacement vs. time at selected points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Get target coordinates\n",
    "c1 = [2.5, 0]\n",
    "c2 = [2.5, 5]\n",
    "# Coordinate indices\n",
    "grididx1 = np.where((obsg_full[:, 0]==c1[0]) & (obsg_full[:, 1]==c1[1]))[0]\n",
    "grididx2 = np.where((obsg_full[:, 0]==c2[0]) & (obsg_full[:, 1]==c2[1]))[0]\n",
    "# Observed and predicted displacements\n",
    "obsdisp1 = e_disp_array[grididx1, :]\n",
    "obsdisp2 = e_disp_array[grididx2, :]\n",
    "preddisp1 = pred_disp[3*grididx1, :]\n",
    "preddisp2 = pred_disp[3*grididx2, :]\n",
    "print((preddisp1[0, -1]-obsdisp1[0, -1])/obsdisp1[0, -1])\n",
    "print((preddisp2[0, -1]-obsdisp2[0, -1])/obsdisp2[0, -1])\n",
    "\n",
    "# Find element centroid nearest target coordinates\n",
    "horiz_centroids = np.mean(horiz_tri_pts, axis=1)\n",
    "dist1 = np.sqrt((horiz_centroids[:, 0] - c1[0])**2 + (horiz_centroids[:, 1] - c1[1])**2)\n",
    "dist2 = np.sqrt((horiz_centroids[:, 0] - c2[0])**2 + (horiz_centroids[:, 1] - c2[1])**2)\n",
    "el_idx1 = np.argmin(dist1)\n",
    "el_idx2 = np.argmin(dist2)\n",
    "slip1 = est_slip[3*(nsource_tri+el_idx1)+1, :]\n",
    "slip2 = est_slip[3*(nsource_tri+el_idx2)+1, :]\n",
    "\n",
    "# Set up figure\n",
    "fig, ax1 = plt.subplots(1, 1, sharex=True, figsize=(7, 4))\n",
    "ax1.plot(time_vector, obsdisp1[0, :], 'b', label=\"(2.5, 0) Relax\")\n",
    "ax1.plot(time_vector, preddisp1[0, :], 'b--', label=\"(2.5, 0) TDE\")\n",
    "ax1.plot(time_vector, obsdisp2[0, :], 'r', label=\"(2.5, 5) Relax\")\n",
    "ax1.plot(time_vector, preddisp2[0, :], 'r--', label=\"(2.5, 5) TDE\")\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('East displacement')\n",
    "ax1.set_title(\"Total displacement\")\n",
    "# axr = ax1.twinx()\n",
    "# axr.plot(time_vector, slip1, 'b--', linewidth=3)\n",
    "# axr.plot(time_vector, slip2, 'r--', linewidth=3)\n",
    "# axr.set_ylabel('Dip-slip')\n",
    "\n",
    "# fig.savefig(f\"png/timeseries.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Relax vs. TDE displacements at different horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_depth1 = 2\n",
    "other_depth2 = 10\n",
    "\n",
    "other_directory1 = directory + \"_\" + str(other_depth1) + \"km\"\n",
    "other_directory2 = directory + \"_\" + str(other_depth2) + \"km\"\n",
    "\n",
    "# Read sequence of displacement grd files \n",
    "e_disp_file_list1 = sorted(glob.glob(other_directory1 + \"/*-relax-east.grd\"))\n",
    "n_disp_file_list1 = sorted(glob.glob(other_directory1 + \"/*-relax-north.grd\"))\n",
    "u_disp_file_list1 = sorted(glob.glob(other_directory1 + \"/*-relax-up.grd\"))\n",
    "\n",
    "# Read sequence of displacement grd files \n",
    "e_disp_file_list2 = sorted(glob.glob(other_directory2 + \"/*-relax-east.grd\"))\n",
    "n_disp_file_list2 = sorted(glob.glob(other_directory2 + \"/*-relax-north.grd\"))\n",
    "u_disp_file_list2 = sorted(glob.glob(other_directory2 + \"/*-relax-up.grd\"))\n",
    "\n",
    "# Get z limits from grdinfo\n",
    "info1 = pygmt.grdinfo(e_disp_file_list1[-1], nearest_multiple=\"+a0.01\")\n",
    "info2 = pygmt.grdinfo(e_disp_file_list2[-1], nearest_multiple=\"+a0.01\")\n",
    "\n",
    "# Allocate space for estimated slip and predicted displacements\n",
    "pred_disp1 = np.zeros((obsg_full.size, len(e_disp_file_list1)))\n",
    "pred_disp2 = np.zeros((obsg_full.size, len(e_disp_file_list2)))\n",
    "\n",
    "# Calculate partials for other depths\n",
    "obsg_full1 = np.array([Xg, Yg, -(other_depth1-0.1)*np.ones_like(Yg)]).reshape((3, -1)).T.copy()\n",
    "disp_mat_full1 = cutde_halfspace.disp_matrix(obs_pts=obsg_full1, tris=horiz_tri_pts, nu=0.25)\n",
    "obsg_full2 = np.array([Xg, Yg, -other_depth2*np.ones_like(Yg)]).reshape((3, -1)).T.copy()\n",
    "disp_mat_full2 = cutde_halfspace.disp_matrix(obs_pts=obsg_full2, tris=horiz_tri_pts, nu=0.25)\n",
    "\n",
    "# Selected time steps\n",
    "sel_times = [20, 30, 70]\n",
    "\n",
    "# Predict displacements at each step \n",
    "# for i in range(len(e_disp_file_list)):\n",
    "for i in sel_times:\n",
    "    # Read Relax displacement components\n",
    "    e_disp1 = pygmt.load_dataarray(e_disp_file_list1[i])\n",
    "    n_disp1 = pygmt.load_dataarray(n_disp_file_list1[i])\n",
    "    u_disp1 = pygmt.load_dataarray(u_disp_file_list1[i])\n",
    "    e_disp2 = pygmt.load_dataarray(e_disp_file_list2[i])\n",
    "    n_disp2 = pygmt.load_dataarray(n_disp_file_list2[i])\n",
    "    u_disp2 = pygmt.load_dataarray(u_disp_file_list2[i])\n",
    "    \n",
    "    # Predict displacements at the full grid resolution at alternate depths \n",
    "    pred_disp1[:, i] = disp_mat_full1.reshape((-1, 3*ntri)).dot(est_slip[:, i])\n",
    "    pred_disp2[:, i] = disp_mat_full2.reshape((-1, 3*ntri)).dot(est_slip[:, i])\n",
    "    \n",
    "    # Convert to grids\n",
    "    eastdispg1 = xa.DataArray.copy(grid)\n",
    "    eastdispg1.values = np.reshape(pred_disp1[0::3, i], (256, 256))\n",
    "    northdispg1 = xa.DataArray.copy(grid)\n",
    "    northdispg1.values = np.reshape(pred_disp1[1::3, i], (256, 256))\n",
    "    updispg1 = xa.DataArray.copy(grid)\n",
    "    updispg1.values = np.reshape(pred_disp1[2::3, i], (256, 256))\n",
    "\n",
    "    eastdispg2 = xa.DataArray.copy(grid)\n",
    "    eastdispg2.values = np.reshape(pred_disp2[0::3, i], (256, 256))\n",
    "    northdispg2 = xa.DataArray.copy(grid)\n",
    "    northdispg2.values = np.reshape(pred_disp2[1::3, i], (256, 256))\n",
    "    updispg2 = xa.DataArray.copy(grid)\n",
    "    updispg2.values = np.reshape(pred_disp2[2::3, i], (256, 256))\n",
    "\n",
    "    # pyGMT figure: 2 panels, TDE and Relax\n",
    "    fig = pygmt.Figure()\n",
    "    pygmt.makecpt(cmap=\"haxby\", series=info1[2:])\n",
    "    with fig.subplot(nrows=1, ncols=2, figsize=(\"22c\", \"6c\")):\n",
    "         with fig.set_panel(panel=0):\n",
    "             # TDE predictions\n",
    "             fig.grdimage(grid=eastdispg1, projection=\"X10c\", frame=[\"ag\"])\n",
    "             fig.colorbar(frame=[\"x+lDisplacement\", \"y+lmm\"])\n",
    "         with fig.set_panel(panel=1):\n",
    "             # Relax grid\n",
    "             fig.grdimage(grid=e_disp1, projection=\"X10c\", frame=[\"ag\"])\n",
    "             fig.colorbar(frame=[\"x+lDisplacement\", \"y+lmm\"])\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig = pygmt.Figure()\n",
    "    with fig.subplot(nrows=1, ncols=2, figsize=(\"22c\", \"6c\")):\n",
    "         with fig.set_panel(panel=0):\n",
    "            # TDE predictions\n",
    "             pygmt.makecpt(cmap=\"haxby\", series='-0.0002/0.0002')\n",
    "             fig.grdimage(grid=eastdispg2, projection=\"X10c\", frame=[\"ag\"])\n",
    "             fig.colorbar(frame=[\"x+lDisplacement\", \"y+lmm\"])\n",
    "         with fig.set_panel(panel=1):\n",
    "             # Relax grid\n",
    "             pygmt.makecpt(cmap=\"haxby\", series=info2[2:])\n",
    "             fig.grdimage(grid=e_disp2, projection=\"X10c\", frame=[\"ag\"])\n",
    "             fig.colorbar(frame=[\"x+lDisplacement\", \"y+lmm\"])\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "print(np.max(e_disp2))\n",
    "print(np.max(eastdispg2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots showing actual TDE slip vs. Relax displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# Predict displacements at each step \n",
    "# for i in range(len(e_disp_file_list)):\n",
    "for i in sel_times:\n",
    "    \n",
    "    # Read Relax displacement components\n",
    "    e_disp1 = pygmt.load_dataarray(e_disp_file_list1[i])\n",
    "    n_disp1 = pygmt.load_dataarray(n_disp_file_list1[i])\n",
    "    u_disp1 = pygmt.load_dataarray(u_disp_file_list1[i])\n",
    "\n",
    "    # Write mesh slip file\n",
    "    fid = open(\"meshes.txt\", \"w\")\n",
    "    for j in range(len(meshes[1].verts)):\n",
    "      line = \"> -Z{}\\n{}, {}\\n{}, {}\\n{}, {}\\n\".format(-est_slip[3*nsource_tri+3*j+1, i],\n",
    "         meshes[1].coords[meshes[1].verts[j, 0], 0],\n",
    "         meshes[1].coords[meshes[1].verts[j, 0], 1],\n",
    "         meshes[1].coords[meshes[1].verts[j, 1], 0],\n",
    "         meshes[1].coords[meshes[1].verts[j, 1], 1],\n",
    "         meshes[1].coords[meshes[1].verts[j, 2], 0],\n",
    "         meshes[1].coords[meshes[1].verts[j, 2], 1])\n",
    "      fid.write(line)\n",
    "    fid.close()\n",
    "\n",
    "    # pyGMT figure: 2 panels, TDE and Relax\n",
    "    fig = pygmt.Figure()\n",
    "    pygmt.makecpt(cmap=\"haxby\", series=info1[2:])\n",
    "    with fig.subplot(nrows=1, ncols=2, figsize=(\"22c\", \"6c\")):\n",
    "         with fig.set_panel(panel=0):\n",
    "            # TDE estimated slip\n",
    "            fig.plot(\"meshes.txt\", close=True, cmap=True, region=[min(xg), max(xg), min(yg), max(yg)], projection=\"X10c\", frame=[\"ag\"])\n",
    "            fig.colorbar(frame=[\"x+lSlip\", \"y+lmm\"])\n",
    "         with fig.set_panel(panel=1):\n",
    "            # Relax grid\n",
    "            fig.grdimage(grid=e_disp1, projection=\"X10c\", frame=[\"ag\"])\n",
    "            fig.colorbar(frame=[\"x+lDisplacement\", \"y+lmm\"])\n",
    "\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelength of estimated slip\n",
    "\n",
    "Interpolate slip at `y=0` and look at profile. Calculate full-width half-max. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "\n",
    "plt.close(\"all\")\n",
    "# Define profile across middle of mesh\n",
    "xprofile = np.linspace(-10, 10)\n",
    "yprofile = 0*xprofile\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "peakpeak = np.zeros(len(time_vector))\n",
    "peakpeakwidth = np.zeros(len(time_vector))\n",
    "\n",
    "for i in range(1,len(time_vector)):\n",
    "    # Interpolate dip slip\n",
    "    interp = LinearNDInterpolator(list(zip(horiz_centroids[:, 0], horiz_centroids[:, 1])), est_slip[1::3, i])\n",
    "    interp_slip = interp(xprofile, yprofile)\n",
    "    # Find peaks of interpolated slip\n",
    "    peaks, _ = find_peaks(interp_slip, 0)\n",
    "    # Find peak widths\n",
    "    fwhm = peak_widths(interp_slip, peaks, rel_height=0.5)\n",
    "    peakpeak = np.argmax(interp_slip[peaks])\n",
    "    peakpeakwidth[i] = fwhm[0][peakpeak]\n",
    "    # ax.plot(interp_slip)\n",
    "    # ax.plot(peaks, interp_slip[peaks], \"x\")\n",
    "    # ax.hlines(*fwhm[1:], color=\"red\")\n",
    "\n",
    "ax.plot(time_vector[1:], peakpeakwidth[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = np.argmax(interp_slip[peaks])\n",
    "print(fwhm[0][ii]*(20/49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9db77a64a61e4dcdfbbb2dda9aea9044a427395acdc27b94ca04048540f5e665"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
